#!/usr/bin/env python3
"""
–£–º–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö —Ñ–∞–∫—Ç–æ–≤ —Å PubMedBERT
"""

import torch
from transformers import AutoTokenizer, AutoModel, pipeline
import re
import json
import numpy as np
from typing import Dict, List, Any

class MedicalFactExtractor:
    def __init__(self):
        self.model_name = "microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract"
        self.tokenizer = None
        self.model = None
        self.ner_pipeline = None
        
    def load_model(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç PubMedBERT –∏ NER pipeline"""
        print("üöÄ –ó–∞–≥—Ä—É–∂–∞–µ–º PubMedBERT –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ñ–∞–∫—Ç–æ–≤...")
        
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        self.model = AutoModel.from_pretrained(self.model_name)
        
        # NER pipeline –¥–ª—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π
        self.ner_pipeline = pipeline(
            "token-classification",
            model="d4data/biomedical-ner-all",
            tokenizer="d4data/biomedical-ner-all",
            aggregation_strategy="simple"
        )
        
        print("‚úÖ –ú–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")
    
    def extract_facts(self, text: str, entities: List[str]) -> Dict[str, Any]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ —Ñ–∞–∫—Ç—ã
        
        Args:
            text: –ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π —Ç–µ–∫—Å—Ç (–∞–±—Å—Ç—Ä–∞–∫—Ç —Å—Ç–∞—Ç—å–∏)
            entities: –¢–∏–ø—ã —Å—É—â–Ω–æ—Å—Ç–µ–π –¥–ª—è –ø–æ–∏—Å–∫–∞
        
        Returns:
            –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è—Ö
        """
        if not self.model:
            self.load_model()
        
        # 1. –ù–∞—Ö–æ–¥–∏–º –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏
        entities_found = self.ner_pipeline(text)
        
        # 2. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è
        interactions = self._analyze_interactions(text, entities_found)
        
        # 3. –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–æ–∑–∏—Ä–æ–≤–∫–∏ –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
        safety_info = self._extract_safety_info(text)
        
        # 4. –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–ª–∏–Ω–∏—á–µ—Å–∫—É—é –∑–Ω–∞—á–∏–º–æ—Å—Ç—å
        clinical_significance = self._assess_clinical_significance(text)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º numpy —Ç–∏–ø—ã –≤ Python —Ç–∏–ø—ã –¥–ª—è JSON
        def convert_numpy_types(obj):
            if isinstance(obj, np.integer):
                return int(obj)
            elif isinstance(obj, np.floating):
                return float(obj)
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, dict):
                return {key: convert_numpy_types(value) for key, value in obj.items()}
            elif isinstance(obj, list):
                return [convert_numpy_types(item) for item in obj]
            return obj
        
        result = {
            "entities": entities_found,
            "interactions": interactions,
            "safety": safety_info,
            "clinical_significance": clinical_significance,
            "confidence_score": self._calculate_confidence(text, entities_found)
        }
        
        return convert_numpy_types(result)
    
    def _analyze_interactions(self, text: str, entities: List[Dict]) -> List[Dict]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ª–µ–∫–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è"""
        interactions = []
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π
        interaction_patterns = {
            "inhibition": [
                r"(\w+)\s+inhibits?\s+(\w+)",
                r"(\w+)\s+blocks?\s+(\w+)",
                r"(\w+)\s+reduces?\s+(\w+)\s+activity"
            ],
            "induction": [
                r"(\w+)\s+induces?\s+(\w+)",
                r"(\w+)\s+increases?\s+(\w+)\s+expression",
                r"(\w+)\s+upregulates?\s+(\w+)"
            ],
            "substrate": [
                r"(\w+)\s+is\s+metabolized\s+by\s+(\w+)",
                r"(\w+)\s+substrate\s+of\s+(\w+)"
            ]
        }
        
        for interaction_type, patterns in interaction_patterns.items():
            for pattern in patterns:
                matches = re.finditer(pattern, text, re.IGNORECASE)
                for match in matches:
                    interactions.append({
                        "type": interaction_type,
                        "subject": match.group(1),
                        "object": match.group(2),
                        "evidence": match.group(0),
                        "strength": self._assess_interaction_strength(match.group(0))
                    })
        
        return interactions
    
    def _extract_safety_info(self, text: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏"""
        safety_keywords = {
            "adverse_effects": ["side effect", "adverse", "toxicity", "harmful"],
            "contraindications": ["contraindicated", "avoid", "not recommended"],
            "warnings": ["caution", "warning", "monitor", "careful"],
            "dosage": ["mg", "dose", "dosage", "daily", "twice daily"]
        }
        
        safety_info = {}
        
        for category, keywords in safety_keywords.items():
            findings = []
            for keyword in keywords:
                if keyword.lower() in text.lower():
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤–æ–∫—Ä—É–≥ –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞
                    context = self._extract_context(text, keyword, window=50)
                    if context:
                        findings.append(context)
            
            safety_info[category] = findings
        
        return safety_info
    
    def _assess_clinical_significance(self, text: str) -> str:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–ª–∏–Ω–∏—á–µ—Å–∫—É—é –∑–Ω–∞—á–∏–º–æ—Å—Ç—å"""
        high_significance = ["clinically significant", "major", "severe", "contraindicated"]
        moderate_significance = ["moderate", "monitor", "caution"]
        low_significance = ["minor", "unlikely", "minimal"]
        
        text_lower = text.lower()
        
        if any(term in text_lower for term in high_significance):
            return "high"
        elif any(term in text_lower for term in moderate_significance):
            return "moderate"
        elif any(term in text_lower for term in low_significance):
            return "low"
        else:
            return "unknown"
    
    def _assess_interaction_strength(self, evidence: str) -> str:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç —Å–∏–ª—É –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è"""
        strong_terms = ["strongly", "significantly", "markedly", "potent"]
        moderate_terms = ["moderately", "modestly", "partial"]
        weak_terms = ["slightly", "minimal", "weak", "minor"]
        
        evidence_lower = evidence.lower()
        
        if any(term in evidence_lower for term in strong_terms):
            return "strong"
        elif any(term in evidence_lower for term in moderate_terms):
            return "moderate"
        elif any(term in evidence_lower for term in weak_terms):
            return "weak"
        else:
            return "moderate"  # default
    
    def _extract_context(self, text: str, keyword: str, window: int = 50) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤–æ–∫—Ä—É–≥ –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞"""
        import re
        
        pattern = rf".{{0,{window}}}{re.escape(keyword)}.{{0,{window}}}"
        match = re.search(pattern, text, re.IGNORECASE)
        
        return match.group(0) if match else ""
    
    def _calculate_confidence(self, text: str, entities: List[Dict]) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π
        # –∏ –Ω–∞–ª–∏—á–∏—è –∫–ª—é—á–µ–≤—ã—Ö –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
        
        entity_score = min(len(entities) / 10, 1.0)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ 1.0
        
        medical_terms = ["metabolism", "enzyme", "cytochrome", "inhibition", "interaction"]
        term_score = sum(1 for term in medical_terms if term in text.lower()) / len(medical_terms)
        
        return (entity_score + term_score) / 2

def test_smart_extraction():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —É–º–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ–∞–∫—Ç–æ–≤"""
    
    extractor = MedicalFactExtractor()
    
    # –¢–µ—Å—Ç–æ–≤—ã–π –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π —Ç–µ–∫—Å—Ç
    test_text = """
    Curcumin significantly inhibits CYP3A4 enzyme activity in a dose-dependent manner. 
    At therapeutic doses (500-1000 mg daily), curcumin moderately reduces the metabolism 
    of CYP3A4 substrates, potentially leading to increased drug concentrations. 
    Patients taking warfarin should exercise caution when using turmeric supplements, 
    as this interaction may increase bleeding risk. Clinical monitoring is recommended.
    """
    
    print("üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º —É–º–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ–∞–∫—Ç–æ–≤...")
    print(f"üìÑ –¢–µ–∫—Å—Ç: {test_text[:100]}...")
    
    facts = extractor.extract_facts(
        text=test_text,
        entities=["supplement", "enzyme", "drug", "interaction"]
    )
    
    print("\nüìä –ò–ó–í–õ–ï–ß–ï–ù–ù–´–ï –§–ê–ö–¢–´:")
    print(json.dumps(facts, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    test_smart_extraction()