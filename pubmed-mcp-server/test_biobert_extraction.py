#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è BioBERT –∏ PubMedBERT
–ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –æ–Ω–∏ —Ä–µ–∞–ª—å–Ω–æ –∏–∑–≤–ª–µ–∫–∞—é—Ç –∏–∑ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤
"""

import torch
from transformers import AutoTokenizer, AutoModel, pipeline
import re
import json
from typing import Dict, List, Any

class BiomedicalExtractorTester:
    def __init__(self):
        self.models = {}
        self.tokenizers = {}
        self.ner_pipelines = {}
        
        # –ú–æ–¥–µ–ª–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        self.model_configs = {
            "PubMedBERT": "microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract",
            "BioBERT": "dmis-lab/biobert-base-cased-v1.2",
            "BlueBERT": "bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12"
        }
        
    def load_models(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
        print("üöÄ –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è...")
        
        for model_name, model_path in self.model_configs.items():
            try:
                print(f"   üì¶ –ó–∞–≥—Ä—É–∂–∞–µ–º {model_name}...")
                
                # –û—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å
                self.tokenizers[model_name] = AutoTokenizer.from_pretrained(model_path)
                self.models[model_name] = AutoModel.from_pretrained(model_path)
                
                # NER pipeline (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
                try:
                    self.ner_pipelines[model_name] = pipeline(
                        "token-classification",
                        model=model_path,
                        tokenizer=model_path,
                        aggregation_strategy="simple"
                    )
                    print(f"   ‚úÖ {model_name} –∑–∞–≥—Ä—É–∂–µ–Ω —Å NER")
                except:
                    print(f"   ‚ö†Ô∏è  {model_name} –∑–∞–≥—Ä—É–∂–µ–Ω –±–µ–∑ NER")
                    
            except Exception as e:
                print(f"   ‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {model_name}: {e}")
    
    def load_supplement_data(self, json_path: str) -> List[Dict]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ supplement_data_avocado.json"""
        try:
            print(f"üìÇ –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑: {json_path}")
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∞–±—Å—Ç—Ä–∞–∫—Ç—ã –∏–∑ –≤—Å–µ—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
            all_abstracts = []
            
            # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º —Å–µ–∫—Ü–∏—è–º –¥–∞–Ω–Ω—ã—Ö
            for section_name, section_data in data.items():
                if isinstance(section_data, dict):
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É: –º–æ–∂–µ—Ç –±—ã—Ç—å 'results' –∏–ª–∏ 'articles'
                    articles_dict = None
                    if 'results' in section_data:
                        articles_dict = section_data['results']
                    elif 'articles' in section_data:
                        articles_dict = section_data['articles']
                    elif section_name in ['meta_analysis', 'rct_mesh', 'rct_tiab', 'clinical_trials', 'human_studies', 
                                        'safety_adverse', 'safety_case_reports', 'interactions', 'pharmacology', 
                                        'mechanisms', 'bioavailability', 'body_systems']:
                        # –ï—Å–ª–∏ —ç—Ç–æ –æ—Å–Ω–æ–≤–Ω–∞—è —Å–µ–∫—Ü–∏—è, –∏—â–µ–º articles –≤–Ω—É—Ç—Ä–∏
                        articles_dict = section_data.get('articles', {})
                    
                    if articles_dict:
                        print(f"   üìä –°–µ–∫—Ü–∏—è {section_name}: {len(articles_dict)} –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π")
                        
                        for pmid, study_data in articles_dict.items():
                            if isinstance(study_data, dict) and 'abstract' in study_data:
                                abstract_text = study_data['abstract']
                                if abstract_text and len(abstract_text.strip()) > 50:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞
                                    all_abstracts.append({
                                        'pmid': pmid,
                                        'section': section_name,
                                        'title': study_data.get('title', ''),
                                        'abstract': abstract_text,
                                        'journal': study_data.get('journal', ''),
                                        'authors': study_data.get('authors', [])
                                    })
            
            print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(all_abstracts)} –∞–±—Å—Ç—Ä–∞–∫—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            return all_abstracts
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
            return []

    def test_real_pubmed_abstracts(self, supplement_data_path: str = None):
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∞–±—Å—Ç—Ä–∞–∫—Ç–∞—Ö"""
        
        if supplement_data_path:
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∞–≤–æ–∫–∞–¥–æ
            print("\n" + "="*80)
            print("ü•ë –ê–ù–ê–õ–ò–ó –†–ï–ê–õ–¨–ù–´–• –î–ê–ù–ù–´–• –ê–í–û–ö–ê–î–û –ò–ó PUBMED")
            print("="*80)
            
            abstracts_data = self.load_supplement_data(supplement_data_path)
            if not abstracts_data:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–º–µ—Ä—ã")
                self.test_sample_abstracts()
                return
            
            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 20 –∞–±—Å—Ç—Ä–∞–∫—Ç–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (—á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å)
            sample_abstracts = abstracts_data[:20]
            
            print(f"\nüìä –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º {len(sample_abstracts)} –∞–±—Å—Ç—Ä–∞–∫—Ç–æ–≤ –∏–∑ {len(abstracts_data)} –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –º–æ–¥–µ–ª—è–º
            model_stats = {model: {'total_entities': 0, 'processed': 0} for model in self.models.keys()}
            all_extracted_data = []
            
            for i, abstract_data in enumerate(sample_abstracts):
                print(f"\nüìÑ –ê–ë–°–¢–†–ê–ö–¢ {i+1}/{len(sample_abstracts)}")
                print(f"   PMID: {abstract_data['pmid']}")
                print(f"   –°–µ–∫—Ü–∏—è: {abstract_data['section']}")
                print(f"   –ó–∞–≥–æ–ª–æ–≤–æ–∫: {abstract_data['title'][:100]}...")
                print("-" * 60)
                
                abstract_text = abstract_data['abstract']
                
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª—å—é
                abstract_results = {
                    'pmid': abstract_data['pmid'],
                    'section': abstract_data['section'],
                    'title': abstract_data['title'],
                    'models': {}
                }
                
                for model_name in self.models.keys():
                    print(f"\nü§ñ {model_name}:")
                    
                    # NER –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ
                    entities = self.extract_entities(abstract_text, model_name)
                    model_stats[model_name]['total_entities'] += len(entities)
                    model_stats[model_name]['processed'] += 1
                    
                    # –°–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
                    specific_data = self.extract_specific_medical_data(abstract_text)
                    
                    print(f"   üìä NER —Å—É—â–Ω–æ—Å—Ç–∏: {len(entities)}")
                    print(f"   üéØ CYP450: {len(specific_data['cyp450'])}")
                    print(f"   üéØ –î–æ–∑–∏—Ä–æ–≤–∫–∏: {len(specific_data['dosages'])}")
                    print(f"   üéØ –ü–æ–±–æ—á–Ω—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã: {len(specific_data['adverse_effects'])}")
                    print(f"   üéØ –ö–∏–Ω–µ—Ç–∏—á–µ—Å–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è: {len(specific_data['kinetic_values'])}")
                    print(f"   üéØ –£—á–∞—Å—Ç–Ω–∏–∫–∏: {len(specific_data['study_participants'])}")
                    print(f"   üéØ –ë–∏–æ–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å: {len(specific_data['bioavailability'])}")
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                    abstract_results['models'][model_name] = {
                        'entities_count': len(entities),
                        'entities': entities[:5],  # –ü–µ—Ä–≤—ã–µ 5 –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
                        'extracted_data': specific_data
                    }
                
                all_extracted_data.append(abstract_results)
            
            # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            print("\n" + "="*80)
            print("üìà –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –ú–û–î–ï–õ–Ø–ú")
            print("="*80)
            
            for model_name, stats in model_stats.items():
                avg_entities = stats['total_entities'] / stats['processed'] if stats['processed'] > 0 else 0
                print(f"\nü§ñ {model_name}:")
                print(f"   üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∞–±—Å—Ç—Ä–∞–∫—Ç–æ–≤: {stats['processed']}")
                print(f"   üìä –í—Å–µ–≥–æ —Å—É—â–Ω–æ—Å—Ç–µ–π: {stats['total_entities']}")
                print(f"   üìä –í —Å—Ä–µ–¥–Ω–µ–º –Ω–∞ –∞–±—Å—Ç—Ä–∞–∫—Ç: {avg_entities:.1f}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–¥—Ä–æ–±–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            output_file = '/Users/yurygagarin/Code/1/vitaplus/pubmed-mcp-server/avocado_analysis_results.json'
            try:
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(all_extracted_data, f, indent=2, ensure_ascii=False)
                print(f"\nüíæ –ü–æ–¥—Ä–æ–±–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_file}")
            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã: {e}")
        else:
            self.test_sample_abstracts()
    
    def test_sample_abstracts(self):
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –Ω–∞ –ø—Ä–∏–º–µ—Ä–∞—Ö –∞–±—Å—Ç—Ä–∞–∫—Ç–æ–≤ (fallback)"""
        
        # –†–µ–∞–ª—å–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –∞–±—Å—Ç—Ä–∞–∫—Ç–æ–≤
        test_abstracts = {
            "curcumin_cyp": """
            Background: Curcumin significantly inhibits cytochrome P450 3A4 (CYP3A4) enzyme activity 
            in human liver microsomes with an IC50 value of 8.2 ŒºM. This study investigated the clinical 
            significance of curcumin-drug interactions.
            
            Methods: Healthy volunteers (n=24) received curcumin 500 mg twice daily for 14 days. 
            CYP3A4 activity was assessed using midazolam 2 mg as a probe substrate.
            
            Results: Curcumin decreased midazolam clearance by 35% (p<0.01), increasing AUC from 
            12.3 ¬± 2.1 to 18.7 ¬± 3.4 ng¬∑h/mL. Tmax increased from 0.8 to 1.2 hours. Two subjects 
            experienced mild nausea. No serious adverse events occurred.
            
            Conclusion: Curcumin moderately inhibits CYP3A4 and may cause clinically significant 
            interactions with CYP3A4 substrates like statins and calcium channel blockers.
            """,
            
            "magnesium_safety": """
            Background: Magnesium supplementation is generally well-tolerated, but high doses 
            may cause gastrointestinal side effects.
            
            Methods: A systematic review of 15 randomized controlled trials (n=1,847) evaluated 
            magnesium safety at doses ranging from 200-800 mg daily.
            
            Results: Diarrhea occurred in 23% of subjects taking >400 mg daily vs 8% with placebo 
            (p<0.001). Nausea was reported in 12% vs 4% (p<0.05). No cases of hypermagnesemia 
            were observed in subjects with normal kidney function. Bioavailability was 45% for 
            magnesium oxide and 68% for magnesium glycinate.
            
            Contraindications: Avoid in severe renal impairment (GFR <30 mL/min). Use caution 
            with digoxin and aminoglycosides.
            """,
            
            "no_data_supplement": """
            Background: Lion's Mane mushroom (Hericium erinaceus) contains hericenones and 
            erinacines that may support cognitive function.
            
            Methods: This preliminary study examined the neuroprotective effects in cell culture.
            
            Results: Beta-glucans showed antioxidant activity in vitro. No human pharmacokinetic 
            data is available. Drug interactions have not been studied.
            
            Conclusion: More research is needed to determine safety and efficacy in humans.
            """
        }
        
        print("\n" + "="*80)
        print("üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ò–ó–í–õ–ï–ß–ï–ù–ò–Ø –î–ê–ù–ù–´–• –ò–ó –†–ï–ê–õ–¨–ù–´–• –ê–ë–°–¢–†–ê–ö–¢–û–í")
        print("="*80)
        
        for abstract_name, abstract_text in test_abstracts.items():
            print(f"\nüìÑ –ê–ë–°–¢–†–ê–ö–¢: {abstract_name.upper()}")
            print("-" * 60)
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é –º–æ–¥–µ–ª—å
            for model_name in self.models.keys():
                print(f"\nü§ñ –ú–û–î–ï–õ–¨: {model_name}")
                
                # 1. NER –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ
                entities = self.extract_entities(abstract_text, model_name)
                print(f"   üìä –ù–∞–π–¥–µ–Ω–æ —Å—É—â–Ω–æ—Å—Ç–µ–π: {len(entities)}")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 —Å—É—â–Ω–æ—Å—Ç–µ–π
                for i, entity in enumerate(entities[:5]):
                    print(f"      {i+1}. {entity.get('word', 'N/A')} -> {entity.get('entity_group', 'N/A')} (conf: {entity.get('score', 0):.2f})")
                
                # 2. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
                specific_data = self.extract_specific_medical_data(abstract_text)
                print(f"   üéØ CYP450 –¥–∞–Ω–Ω—ã–µ: {len(specific_data['cyp450'])}")
                print(f"   üéØ –î–æ–∑–∏—Ä–æ–≤–∫–∏: {len(specific_data['dosages'])}")
                print(f"   üéØ –ü–æ–±–æ—á–Ω—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã: {len(specific_data['adverse_effects'])}")
                print(f"   üéØ IC50/Ki –∑–Ω–∞—á–µ–Ω–∏—è: {len(specific_data['kinetic_values'])}")
    
    def extract_entities(self, text: str, model_name: str) -> List[Dict]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏ —Å –ø–æ–º–æ—â—å—é NER"""
        if model_name in self.ner_pipelines:
            try:
                entities = self.ner_pipelines[model_name](text)
                return entities
            except Exception as e:
                print(f"      ‚ùå –û—à–∏–±–∫–∞ NER –¥–ª—è {model_name}: {e}")
        
        return []
    
    def extract_specific_medical_data(self, text: str) -> Dict[str, List]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ —Å –ø–æ–º–æ—â—å—é regex"""
        
        data = {
            "cyp450": [],
            "dosages": [],
            "adverse_effects": [],
            "kinetic_values": [],
            "study_participants": [],
            "bioavailability": [],
            "contraindications": []
        }
        
        # CYP450 –¥–∞–Ω–Ω—ã–µ
        cyp_patterns = [
            r'(CYP\w+)\s+(?:activity|enzyme)',
            r'cytochrome\s+p450\s+(\w+)',
            r'(CYP\w+)\s+(?:inhibition|substrate|induction)'
        ]
        
        for pattern in cyp_patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                data["cyp450"].append({
                    "enzyme": match.group(1),
                    "context": match.group(0)
                })
        
        # –î–æ–∑–∏—Ä–æ–≤–∫–∏
        dosage_patterns = [
            r'(\d+(?:\.\d+)?)\s*(mg|g|mcg|Œºg)\s+(?:daily|twice\s+daily|once\s+daily)',
            r'doses?\s+(?:of\s+)?(\d+(?:\.\d+)?)\s*(mg|g|mcg|Œºg)',
            r'(\d+(?:\.\d+)?)\s*(mg|g|mcg|Œºg)\s+(?:per\s+day|bid|tid)'
        ]
        
        for pattern in dosage_patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                data["dosages"].append({
                    "amount": match.group(1),
                    "unit": match.group(2),
                    "context": match.group(0)
                })
        
        # –ö–∏–Ω–µ—Ç–∏—á–µ—Å–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
        kinetic_patterns = [
            r'ic50[^\d]*(\d+(?:\.\d+)?)\s*(nm|Œºm|mm)',
            r'ki[^\d]*(\d+(?:\.\d+)?)\s*(nm|Œºm|mm)',
            r'auc[^\d]*(\d+(?:\.\d+)?)',
            r'tmax[^\d]*(\d+(?:\.\d+)?)\s*(hours?|h|min)'
        ]
        
        for pattern in kinetic_patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                data["kinetic_values"].append({
                    "parameter": pattern.split('[')[0],
                    "value": match.group(1),
                    "unit": match.group(2) if len(match.groups()) > 1 else "",
                    "context": match.group(0)
                })
        
        # –ü–æ–±–æ—á–Ω—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã
        ae_patterns = [
            r'(nausea|diarrhea|headache|dizziness)\s+(?:occurred\s+in\s+)?(\d+)%',
            r'(\d+)%\s+(?:of\s+(?:subjects|patients))?\s+experienced\s+(\w+)',
            r'side\s+effects?\s+include[d]?\s+([^.]+)'
        ]
        
        for pattern in ae_patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                data["adverse_effects"].append({
                    "effect": match.group(1) if match.group(1) else match.group(2),
                    "frequency": match.group(2) if match.group(2) and match.group(2).isdigit() else None,
                    "context": match.group(0)
                })
        
        # –£—á–∞—Å—Ç–Ω–∏–∫–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
        participant_patterns = [
            r'(?:n\s*=\s*)?(\d+)\s+(?:subjects?|patients?|volunteers?)',
            r'(\d+)\s+(?:healthy\s+)?(?:adults?|participants?)'
        ]
        
        for pattern in participant_patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                data["study_participants"].append({
                    "count": int(match.group(1)),
                    "context": match.group(0)
                })
        
        # –ë–∏–æ–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
        bioavail_patterns = [
            r'bioavailability[^\d]*(\d+(?:\.\d+)?)%',
            r'(\d+(?:\.\d+)?)%\s+bioavailable'
        ]
        
        for pattern in bioavail_patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                data["bioavailability"].append({
                    "value": float(match.group(1)),
                    "context": match.group(0)
                })
        
        # –ü—Ä–æ—Ç–∏–≤–æ–ø–æ–∫–∞–∑–∞–Ω–∏—è
        contraind_patterns = [
            r'contraindicated?\s+in\s+([^.]+)',
            r'avoid\s+in\s+([^.]+)',
            r'not\s+recommended\s+(?:for|in)\s+([^.]+)'
        ]
        
        for pattern in contraind_patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                data["contraindications"].append({
                    "condition": match.group(1).strip(),
                    "context": match.group(0)
                })
        
        return data
    
    def compare_model_performance(self):
        """–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        
        test_sentences = [
            "Curcumin inhibits CYP3A4 with IC50 of 8.2 ŒºM",
            "Patients received magnesium 400 mg twice daily",
            "Nausea occurred in 23% of subjects taking high doses",
            "Contraindicated in severe renal impairment",
            "Bioavailability was 45% for oral administration"
        ]
        
        print("\n" + "="*80)
        print("‚öñÔ∏è  –°–†–ê–í–ù–ï–ù–ò–ï –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò –ú–û–î–ï–õ–ï–ô")
        print("="*80)
        
        for sentence in test_sentences:
            print(f"\nüìù –¢–ï–°–¢–û–í–û–ï –ü–†–ï–î–õ–û–ñ–ï–ù–ò–ï:")
            print(f"   {sentence}")
            print("-" * 60)
            
            for model_name in self.models.keys():
                entities = self.extract_entities(sentence, model_name)
                print(f"ü§ñ {model_name}: {len(entities)} —Å—É—â–Ω–æ—Å—Ç–µ–π")
                
                for entity in entities:
                    print(f"   ‚Ä¢ {entity.get('word', 'N/A')} -> {entity.get('entity_group', 'N/A')}")
    
    def test_edge_cases(self):
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —Å–ª–æ–∂–Ω—ã–µ —Å–ª—É—á–∞–∏"""
        
        edge_cases = {
            "complex_dosing": "Curcumin 500 mg twice daily with food, increased to 1000 mg if well tolerated",
            "multiple_cyp": "The compound inhibits CYP3A4, CYP2D6, and CYP2C9 with different potencies", 
            "conditional_effects": "Side effects were dose-dependent: 10% at 200 mg, 25% at 400 mg, 45% at 800 mg",
            "no_clear_data": "Drug interactions have not been studied in this population",
            "conflicting_data": "One study reported 30% bioavailability while another found 55%"
        }
        
        print("\n" + "="*80)
        print("üé≠ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –°–õ–û–ñ–ù–´–• –°–õ–£–ß–ê–ï–í")
        print("="*80)
        
        for case_name, case_text in edge_cases.items():
            print(f"\nüîç –°–õ–£–ß–ê–ô: {case_name}")
            print(f"üìù –¢–µ–∫—Å—Ç: {case_text}")
            print("-" * 60)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            extracted = self.extract_specific_medical_data(case_text)
            
            print("üìä –ò–ó–í–õ–ï–ß–ï–ù–û:")
            for data_type, items in extracted.items():
                if items:
                    print(f"   {data_type}: {len(items)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
                    for item in items[:2]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 2
                        print(f"      ‚Ä¢ {item}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    
    print("üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ë–ò–û–ú–ï–î–ò–¶–ò–ù–°–ö–ò–• –ú–û–î–ï–õ–ï–ô")
    print("="*80)
    print("–ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ BioBERT, PubMedBERT –∏ BlueBERT —Ä–µ–∞–ª—å–Ω–æ –∏–∑–≤–ª–µ–∫–∞—é—Ç")
    print("–∏–∑ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤ –ø–µ—Ä–µ–¥ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π –≤ MCP —Å–µ—Ä–≤–µ—Ä")
    print("="*80)
    
    # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –¥–∞–Ω–Ω—ã–º–∏ –∞–≤–æ–∫–∞–¥–æ
    supplement_data_path = "/Users/yurygagarin/Code/vitaplus-supplement-analyzer/supplement_data_avocado.json"
    
    tester = BiomedicalExtractorTester()
    
    try:
        # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏
        tester.load_models()
        
        # 2. –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∞–≤–æ–∫–∞–¥–æ
        print(f"\nü•ë –ë—É–¥–µ–º –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∞–≤–æ–∫–∞–¥–æ –∏–∑ PubMed")
        print(f"üìÇ –§–∞–π–ª: {supplement_data_path}")
        tester.test_real_pubmed_abstracts(supplement_data_path)
        
        # 3. –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö
        tester.compare_model_performance()
        
        # 4. –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å–ª–æ–∂–Ω—ã–µ —Å–ª—É—á–∞–∏
        tester.test_edge_cases()
        
        print("\n" + "="*80)
        print("‚úÖ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")
        print("="*80)
        print("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∫–∞–∂—É—Ç:")
        print("‚Ä¢ –ö–∞–∫–∏–µ –º–æ–¥–µ–ª–∏ –ª—É—á—à–µ –¥–ª—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∞–≤–æ–∫–∞–¥–æ")
        print("‚Ä¢ –ß—Ç–æ –æ–Ω–∏ –∏–∑–≤–ª–µ–∫–∞—é—Ç –∏–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π")
        print("‚Ä¢ –°—Ç–æ–∏—Ç –ª–∏ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –≤ MCP —Å–µ—Ä–≤–µ—Ä")
        print("‚Ä¢ –ü–æ–¥—Ä–æ–±–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ avocado_analysis_results.json")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()