#!/usr/bin/env python3
"""
ĞŸÑ€Ğ¾ÑÑ‚Ğ¾Ğ¹ Mistral Ğ±ĞµĞ· MCP - Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
"""

from mlx_lm import load, generate
import sys

def ask_mistral(prompt, max_tokens=500):
    """ĞŸÑ€Ğ¾ÑÑ‚Ğ¾Ğ¹ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğº Mistral"""
    print("ğŸš€ Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Mistral...")
    model, tokenizer = load('mlx-community/Mistral-7B-Instruct-v0.2-4bit')
    print("âœ… Mistral Ğ³Ğ¾Ñ‚Ğ¾Ğ²!")
    
    formatted_prompt = f"[INST] {prompt} [/INST]"
    
    print("ğŸ§  Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¾Ñ‚Ğ²ĞµÑ‚...")
    response = generate(
        model,
        tokenizer,
        prompt=formatted_prompt,
        max_tokens=max_tokens,
        verbose=False
    )
    
    return response

def main():
    if len(sys.argv) > 1:
        query = " ".join(sys.argv[1:])
    else:
        query = input("ğŸ” Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ²Ğ°Ñˆ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ: ")
    
    print(f"\nğŸ” Ğ’Ğ¾Ğ¿Ñ€Ğ¾Ñ: {query}")
    print("="*50)
    
    answer = ask_mistral(query)
    
    print("ğŸ§  ĞÑ‚Ğ²ĞµÑ‚ Mistral:")
    print(answer)

if __name__ == "__main__":
    main()