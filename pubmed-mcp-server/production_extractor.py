#!/usr/bin/env python3
"""
–ü—Ä–æ–¥–∞–∫—à–Ω-–≤–µ—Ä—Å–∏—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞
–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å PubMed –¥–∞–Ω–Ω—ã–º–∏
"""

import torch
from transformers import AutoTokenizer, AutoModel, pipeline
import re
import json
import numpy as np
from typing import Dict, List, Any, Optional

class ProductionMedicalExtractor:
    def __init__(self):
        self.model_name = "microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract"
        self.tokenizer = None
        self.model = None
        self.loaded = False
        
        # –ü—Ä–µ–¥–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏
        self.supplements = [
            "curcumin", "turmeric", "magnesium", "vitamin d", "omega-3", 
            "green tea", "ginkgo", "st john's wort", "echinacea", "garlic",
            "ginseng", "milk thistle", "saw palmetto", "ashwagandha"
        ]
        
        self.enzymes = [
            "cyp3a4", "cyp2d6", "cyp2c9", "cyp2c19", "cyp1a2", 
            "ugt1a1", "ugt2b7", "p-glycoprotein", "cyp2b6"
        ]
        
        self.drugs = [
            "warfarin", "digoxin", "phenytoin", "cyclosporine", "tacrolimus",
            "simvastatin", "atorvastatin", "midazolam", "alprazolam"
        ]
    
    def load_model(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –æ–¥–∏–Ω —Ä–∞–∑"""
        if self.loaded:
            return
            
        print("üöÄ –ó–∞–≥—Ä—É–∂–∞–µ–º PubMedBERT –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–Ω –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è...")
        
        try:
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
            self.model = AutoModel.from_pretrained(self.model_name)
            self.loaded = True
            print("‚úÖ PubMedBERT –∑–∞–≥—Ä—É–∂–µ–Ω!")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
    
    def analyze_pubmed_abstract(self, abstract: str, supplement_name: str = None) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∞–±—Å—Ç—Ä–∞–∫—Ç PubMed —Å—Ç–∞—Ç—å–∏
        
        Args:
            abstract: –¢–µ–∫—Å—Ç –∞–±—Å—Ç—Ä–∞–∫—Ç–∞
            supplement_name: –ù–∞–∑–≤–∞–Ω–∏–µ –¥–æ–±–∞–≤–∫–∏ –¥–ª—è —Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
        
        Returns:
            –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è—Ö
        """
        if not self.loaded:
            self.load_model()
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç–µ–∫—Å—Ç
        text = self._normalize_text(abstract)
        
        # –û—Å–Ω–æ–≤–Ω–æ–π –∞–Ω–∞–ª–∏–∑
        result = {
            "supplement": supplement_name or self._find_primary_supplement(text),
            "interactions": self._extract_interactions(text),
            "safety_signals": self._extract_safety_signals(text),
            "dosage_info": self._extract_dosage_info(text),
            "clinical_evidence": self._assess_evidence_level(text),
            "recommendations": self._extract_recommendations(text),
            "confidence": self._calculate_overall_confidence(text)
        }
        
        return result
    
    def _normalize_text(self, text: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π —Ç–µ–∫—Å—Ç"""
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã
        text = re.sub(r'\s+', ' ', text.strip())
        
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è —Ñ–µ—Ä–º–µ–Ω—Ç–æ–≤
        text = re.sub(r'CYP\s*3A4', 'CYP3A4', text, flags=re.IGNORECASE)
        text = re.sub(r'CYP\s*2D6', 'CYP2D6', text, flags=re.IGNORECASE)
        text = re.sub(r'CYP\s*2C9', 'CYP2C9', text, flags=re.IGNORECASE)
        
        return text
    
    def _find_primary_supplement(self, text: str) -> Optional[str]:
        """–ù–∞—Ö–æ–¥–∏—Ç –æ—Å–Ω–æ–≤–Ω—É—é –¥–æ–±–∞–≤–∫—É –≤ —Ç–µ–∫—Å—Ç–µ"""
        text_lower = text.lower()
        
        for supplement in self.supplements:
            if supplement.lower() in text_lower:
                return supplement
        
        return None
    
    def _extract_interactions(self, text: str) -> List[Dict[str, Any]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è—Ö"""
        interactions = []
        
        # –£–ª—É—á—à–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π
        patterns = {
            "inhibition": [
                r'(\w+(?:\s+\w+)?)\s+(?:significantly|moderately|strongly|potently)?\s*inhibits?\s+(\w+)',
                r'(\w+(?:\s+\w+)?)\s+(?:blocks?|reduces?|decreases?)\s+(\w+)(?:\s+activity)?',
                r'inhibition\s+of\s+(\w+)\s+by\s+(\w+)'
            ],
            "induction": [
                r'(\w+(?:\s+\w+)?)\s+(?:significantly|moderately|strongly)?\s*induces?\s+(\w+)',
                r'(\w+(?:\s+\w+)?)\s+(?:increases?|upregulates?)\s+(\w+)(?:\s+expression)?'
            ],
            "substrate": [
                r'(\w+(?:\s+\w+)?)\s+is\s+(?:a\s+)?substrate\s+(?:of\s+)?(\w+)',
                r'(\w+)\s+metabolizes?\s+(\w+)',
                r'(\w+(?:\s+\w+)?)\s+is\s+metabolized\s+by\s+(\w+)'
            ]
        }
        
        for interaction_type, pattern_list in patterns.items():
            for pattern in pattern_list:
                matches = re.finditer(pattern, text, re.IGNORECASE)
                for match in matches:
                    subject = match.group(1).strip()
                    target = match.group(2).strip()
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ —Ä–µ–∞–ª—å–Ω—ã–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏
                    if self._is_medical_entity(subject) and self._is_medical_entity(target):
                        interaction = {
                            "type": interaction_type,
                            "subject": subject,
                            "target": target,
                            "evidence_text": match.group(0),
                            "strength": self._assess_interaction_strength(match.group(0)),
                            "position": match.span()
                        }
                        interactions.append(interaction)
        
        return interactions
    
    def _extract_safety_signals(self, text: str) -> Dict[str, List[str]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–∏–≥–Ω–∞–ª—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏"""
        safety_signals = {
            "warnings": [],
            "adverse_effects": [],
            "contraindications": [],
            "monitoring_required": []
        }
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π
        patterns = {
            "warnings": [
                r'(?:caution|warning|careful|avoid|risk)[^.]{0,100}',
                r'should\s+(?:be\s+)?(?:avoided|monitored|used\s+carefully)[^.]{0,100}',
                r'may\s+(?:increase|cause|lead\s+to)[^.]{0,100}(?:risk|toxicity|bleeding)'
            ],
            "adverse_effects": [
                r'(?:side\s+effects?|adverse\s+(?:effects?|reactions?)|toxicity)[^.]{0,100}',
                r'(?:nausea|headache|dizziness|bleeding|liver\s+damage)[^.]{0,100}'
            ],
            "contraindications": [
                r'contraindicated[^.]{0,100}',
                r'should\s+not\s+be\s+used[^.]{0,100}',
                r'avoid\s+in\s+patients[^.]{0,100}'
            ],
            "monitoring_required": [
                r'(?:monitor|monitoring|surveillance)[^.]{0,100}',
                r'regular\s+(?:blood\s+tests?|laboratory\s+tests?)[^.]{0,100}'
            ]
        }
        
        for category, pattern_list in patterns.items():
            for pattern in pattern_list:
                matches = re.finditer(pattern, text, re.IGNORECASE)
                for match in matches:
                    safety_signals[category].append(match.group(0).strip())
        
        return safety_signals
    
    def _extract_dosage_info(self, text: str) -> List[Dict[str, str]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ–∑–∏—Ä–æ–≤–∫–∞—Ö"""
        dosage_patterns = [
            r'(\d+(?:\.\d+)?)\s*(?:-\s*(\d+(?:\.\d+)?))?\s*(mg|g|mcg|iu|units?)\s*(?:daily|per\s+day|twice\s+daily)',
            r'therapeutic\s+dose[^.]{0,50}?(\d+(?:\.\d+)?)\s*(mg|g|mcg)',
            r'(?:at\s+)?dose[s]?\s+(?:of\s+)?(\d+(?:\.\d+)?)\s*(mg|g|mcg)'
        ]
        
        dosages = []
        for pattern in dosage_patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                groups = match.groups()
                
                # –ë–µ–∑–æ–ø–∞—Å–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                dosage_info = {
                    "amount": groups[0] if len(groups) > 0 else "unknown",
                    "unit": groups[-1] if len(groups) > 1 else "unknown",
                    "context": match.group(0),
                    "range": groups[1] if len(groups) > 2 and groups[1] else None
                }
                dosages.append(dosage_info)
        
        return dosages
    
    def _assess_evidence_level(self, text: str) -> str:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç —É—Ä–æ–≤–µ–Ω—å –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        high_evidence = ["randomized controlled trial", "meta-analysis", "systematic review", "clinical trial"]
        moderate_evidence = ["cohort study", "case-control", "clinical study", "human study"]
        low_evidence = ["case report", "in vitro", "animal study", "preliminary"]
        
        text_lower = text.lower()
        
        if any(term in text_lower for term in high_evidence):
            return "high"
        elif any(term in text_lower for term in moderate_evidence):
            return "moderate"
        elif any(term in text_lower for term in low_evidence):
            return "low"
        else:
            return "unknown"
    
    def _extract_recommendations(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª–∏–Ω–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"""
        recommendation_patterns = [
            r'(?:recommend|suggestion|should|advise)[^.]{0,100}',
            r'clinical\s+(?:monitoring|surveillance|management)[^.]{0,100}',
            r'patients\s+should[^.]{0,100}'
        ]
        
        recommendations = []
        for pattern in recommendation_patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                recommendations.append(match.group(0).strip())
        
        return recommendations
    
    def _is_medical_entity(self, entity: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—É—â–Ω–æ—Å—Ç—å –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π"""
        entity_lower = entity.lower()
        
        all_entities = self.supplements + self.enzymes + self.drugs
        
        return any(med_entity.lower() in entity_lower or entity_lower in med_entity.lower() 
                  for med_entity in all_entities)
    
    def _assess_interaction_strength(self, evidence: str) -> str:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç —Å–∏–ª—É –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        evidence_lower = evidence.lower()
        
        if any(term in evidence_lower for term in ["significantly", "markedly", "strongly", "potently", "major"]):
            return "strong"
        elif any(term in evidence_lower for term in ["moderately", "modestly", "moderate"]):
            return "moderate"
        elif any(term in evidence_lower for term in ["slightly", "minimally", "weak", "minor"]):
            return "weak"
        else:
            return "moderate"
    
    def _calculate_overall_confidence(self, text: str) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –æ–±—â—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –∞–Ω–∞–ª–∏–∑–µ"""
        factors = []
        
        # –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞
        text_length_score = min(len(text) / 1000, 1.0)
        factors.append(text_length_score)
        
        # –ù–∞–ª–∏—á–∏–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
        medical_terms = ["metabolism", "enzyme", "cytochrome", "inhibition", "interaction", "pharmacokinetic"]
        term_score = sum(1 for term in medical_terms if term in text.lower()) / len(medical_terms)
        factors.append(term_score)
        
        # –ù–∞–ª–∏—á–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        has_dosage = bool(re.search(r'\d+\s*(?:mg|g|mcg)', text))
        has_enzyme = any(enzyme in text.lower() for enzyme in self.enzymes)
        has_supplement = any(supplement in text.lower() for supplement in self.supplements)
        
        specificity_score = sum([has_dosage, has_enzyme, has_supplement]) / 3
        factors.append(specificity_score)
        
        return sum(factors) / len(factors)

def test_production_extractor():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø—Ä–æ–¥–∞–∫—à–Ω —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä"""
    
    extractor = ProductionMedicalExtractor()
    
    # –†–µ–∞–ª—å–Ω—ã–π –ø—Ä–∏–º–µ—Ä –∞–±—Å—Ç—Ä–∞–∫—Ç–∞
    test_abstract = """
    Background: Curcumin, the active component of turmeric, has been shown to interact 
    with cytochrome P450 enzymes. This study investigated the effects of curcumin 
    supplementation on CYP3A4 activity in healthy volunteers.
    
    Methods: Twenty healthy adults received curcumin 500 mg twice daily for 14 days. 
    CYP3A4 activity was assessed using midazolam as a probe substrate.
    
    Results: Curcumin significantly inhibited CYP3A4 activity by 45% (p<0.01). 
    The inhibition was dose-dependent and reversible. Patients taking warfarin 
    should exercise caution when using curcumin supplements due to increased 
    bleeding risk. Clinical monitoring of INR is recommended.
    
    Conclusion: Curcumin moderately inhibits CYP3A4 and may affect the metabolism 
    of CYP3A4 substrates. Healthcare providers should be aware of potential 
    drug-supplement interactions.
    """
    
    print("üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–æ–¥–∞–∫—à–Ω —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä...")
    print("="*70)
    
    result = extractor.analyze_pubmed_abstract(test_abstract, "curcumin")
    
    print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢ –ê–ù–ê–õ–ò–ó–ê:")
    print(json.dumps(result, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    test_production_extractor()