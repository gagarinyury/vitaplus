#!/usr/bin/env python3
"""
ODS Fact Sheets Downloader
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –≤—Å–µ—Ö —Ñ–∞–∫—Ç-–ª–∏—Å—Ç–æ–≤ –æ—Ç NIH Office of Dietary Supplements
"""

import os
import time
import json
import requests
import xml.etree.ElementTree as ET
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional

class ODSFactSheetDownloader:
    def __init__(self, base_dir: str = "ods_fact_sheets"):
        self.base_url = "https://ods.od.nih.gov/api/"
        self.base_dir = Path(base_dir)
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        })
        
        # –°–ø–∏—Å–æ–∫ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤ (—Ä–∞—Å—à–∏—Ä–∏–º –ø–æ –º–µ—Ä–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)
        self.known_resources = [
            # –û—Å–Ω–æ–≤–Ω—ã–µ –≤–∏—Ç–∞–º–∏–Ω—ã
            "VitaminA", "VitaminC", "VitaminD", "VitaminE", "VitaminK",
            "VitaminB6", "VitaminB12", "Folate", "Niacin", "Riboflavin", 
            "Thiamin", "Biotin", "PantothenicAcid",
            
            # –ú–∏–Ω–µ—Ä–∞–ª—ã
            "Calcium", "Iron", "Magnesium", "Zinc", "Selenium", 
            "Chromium", "Copper", "Iodine", "Manganese", "Molybdenum",
            "Phosphorus", "Potassium", "Sodium",
            
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –¥–æ–±–∞–≤–∫–∏
            "Omega3FattyAcids", "Probiotics", "Ashwagandha", "Multivitamin",
            "CoQ10", "Glucosamine", "Chondroitin", "Ginkgo", "Ginseng",
            "Echinacea", "GarlicSupplements", "Turmeric", "Melatonin",
            
            # –ê–º–∏–Ω–æ–∫–∏—Å–ª–æ—Ç—ã –∏ –¥—Ä—É–≥–∏–µ
            "Creatine", "BetaAlanine", "BCAA", "Carnitine", "Taurine",
            
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–µ–º—ã
            "DietarySupplementsExercise", "DietarySupplementsOlderAdults",
            "DietarySupplementsPregnancy", "DietarySupplementsCOVID19",
            "WeightLossSupplements", "EnergyDrinks"
        ]
        
        self.reading_levels = ["Consumer", "HealthProfessional", "Spanish"]
        self.output_formats = ["XML", "HTML"]
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            "total_attempted": 0,
            "successful_downloads": 0,
            "failed_downloads": 0,
            "existing_files": 0
        }

    def setup_directories(self):
        """–°–æ–∑–¥–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫ –¥–ª—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ —Ñ–∞–∫—Ç-–ª–∏—Å—Ç–æ–≤"""
        print("üìÅ –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø–∞–ø–æ–∫...")
        
        for format_type in ["xml", "html", "json"]:
            for level in ["consumer", "health_professional", "spanish"]:
                dir_path = self.base_dir / format_type / level
                dir_path.mkdir(parents=True, exist_ok=True)
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –ª–æ–≥–æ–≤
        (self.base_dir / "logs").mkdir(exist_ok=True)
        
        print(f"‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–ø–æ–∫ —Å–æ–∑–¥–∞–Ω–∞ –≤: {self.base_dir}")

    def test_resource_availability(self, resource: str) -> Dict[str, bool]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Ä–µ—Å—É—Ä—Å–∞ –¥–ª—è –≤—Å–µ—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π —É—Ä–æ–≤–Ω–µ–π –∏ —Ñ–æ—Ä–º–∞—Ç–æ–≤"""
        availability = {}
        
        for level in self.reading_levels:
            for format_type in self.output_formats:
                url = f"{self.base_url}?resourcename={resource}&readinglevel={level}&outputformat={format_type}"
                
                try:
                    response = self.session.get(url, timeout=10)
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –Ω–µ –æ—à–∏–±–∫–∞ –∏–ª–∏ —Ä–µ–¥–∏—Ä–µ–∫—Ç –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –æ—à–∏–±–∫–∏
                    is_available = (
                        response.status_code == 200 and 
                        len(response.content) > 1000 and  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                        b"Error" not in response.content[:500] and
                        b"Not Found" not in response.content[:500]
                    )
                    availability[f"{level}_{format_type}"] = is_available
                    
                except Exception as e:
                    availability[f"{level}_{format_type}"] = False
                
                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                time.sleep(0.5)
        
        return availability

    def download_fact_sheet(self, resource: str, level: str, format_type: str) -> Optional[Dict]:
        """–°–∫–∞—á–∏–≤–∞–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ñ–∞–∫—Ç-–ª–∏—Å—Ç"""
        url = f"{self.base_url}?resourcename={resource}&readinglevel={level}&outputformat={format_type}"
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        level_dir = level.lower().replace("health", "health_")
        file_extension = format_type.lower()
        filename = f"{resource}_{level}_{format_type}.{file_extension}"
        filepath = self.base_dir / file_extension / level_dir / filename
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ñ–∞–π–ª
        if filepath.exists():
            self.stats["existing_files"] += 1
            return {"status": "exists", "path": str(filepath)}
        
        try:
            print(f"üì• –°–∫–∞—á–∏–≤–∞–Ω–∏–µ: {resource} ({level}, {format_type})")
            response = self.session.get(url, timeout=15)
            
            if response.status_code == 200 and len(response.content) > 1000:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
                with open(filepath, 'wb') as f:
                    f.write(response.content)
                
                # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ XML
                metadata = None
                if format_type == "XML":
                    try:
                        metadata = self.extract_metadata_from_xml(response.content)
                    except Exception as e:
                        print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {e}")
                
                self.stats["successful_downloads"] += 1
                return {
                    "status": "success", 
                    "path": str(filepath),
                    "size": len(response.content),
                    "metadata": metadata
                }
            else:
                self.stats["failed_downloads"] += 1
                return {"status": "failed", "reason": f"HTTP {response.status_code} or small content"}
                
        except Exception as e:
            self.stats["failed_downloads"] += 1
            return {"status": "error", "reason": str(e)}

    def extract_metadata_from_xml(self, xml_content: bytes) -> Dict:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ XML-–∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Ñ–∞–∫—Ç-–ª–∏—Å—Ç–∞"""
        try:
            root = ET.fromstring(xml_content.decode('utf-8'))
            
            # –£–±–∏—Ä–∞–µ–º namespace –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –ø–æ–∏—Å–∫–∞
            for elem in root.iter():
                if '}' in elem.tag:
                    elem.tag = elem.tag.split('}')[1]
            
            metadata = {}
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–ª—è
            fields = ['FSID', 'Title', 'ShortTitle', 'LanguageCode', 'Reviewed', 'URL']
            for field in fields:
                elem = root.find(field)
                if elem is not None:
                    metadata[field.lower()] = elem.text
            
            # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è—Ö –∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            content_elem = root.find('Content')
            if content_elem is not None:
                content = content_elem.text or ""
                metadata['has_interactions'] = any(word in content.lower() for word in 
                    ['interact', 'enhance', 'reduce', 'absorb', 'interfere', 'affect'])
                metadata['content_length'] = len(content)
            
            return metadata
            
        except Exception as e:
            return {"error": f"Failed to parse XML: {e}"}

    def save_download_log(self, results: List[Dict]):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ª–æ–≥ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –≤ JSON"""
        log_data = {
            "download_date": datetime.now().isoformat(),
            "stats": self.stats,
            "results": results
        }
        
        log_path = self.base_dir / "logs" / f"download_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        with open(log_path, 'w', encoding='utf-8') as f:
            json.dump(log_data, f, indent=2, ensure_ascii=False)
        
        print(f"üìä –õ–æ–≥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {log_path}")

    def create_summary_report(self, results: List[Dict]):
        """–°–æ–∑–¥–∞–µ—Ç —Å–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç –æ —Å–∫–∞—á–∞–Ω–Ω—ã—Ö —Ñ–∞–∫—Ç-–ª–∏—Å—Ç–∞—Ö"""
        successful_resources = set()
        available_combinations = {}
        metadata_summary = {}
        
        for result in results:
            if result.get("status") in ["success", "exists"]:
                resource = result["resource"]
                level = result["level"] 
                format_type = result["format"]
                
                successful_resources.add(resource)
                
                if resource not in available_combinations:
                    available_combinations[resource] = []
                available_combinations[resource].append(f"{level}_{format_type}")
                
                # –°–æ–±–∏—Ä–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                if result.get("metadata"):
                    metadata_summary[f"{resource}_{level}_{format_type}"] = result["metadata"]
        
        # –°–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç
        report = {
            "summary": {
                "total_resources": len(successful_resources),
                "total_files": self.stats["successful_downloads"] + self.stats["existing_files"],
                "successful_downloads": self.stats["successful_downloads"],
                "existing_files": self.stats["existing_files"],
                "failed_downloads": self.stats["failed_downloads"]
            },
            "available_resources": sorted(list(successful_resources)),
            "resource_combinations": available_combinations,
            "metadata_summary": metadata_summary
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
        report_path = self.base_dir / "summary_report.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"üìã –°–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")
        return report

    def download_all_fact_sheets(self, max_resources: Optional[int] = None):
        """–°–∫–∞—á–∏–≤–∞–µ—Ç –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ–∞–∫—Ç-–ª–∏—Å—Ç—ã"""
        print("üöÄ –ù–∞—á–∏–Ω–∞–µ–º —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–∞–∫—Ç-–ª–∏—Å—Ç–æ–≤ ODS...")
        print(f"üìù –ë—É–¥–µ–º –ø—Ä–æ–≤–µ—Ä—è—Ç—å {len(self.known_resources)} —Ä–µ—Å—É—Ä—Å–æ–≤")
        
        self.setup_directories()
        
        all_results = []
        
        resources_to_process = self.known_resources[:max_resources] if max_resources else self.known_resources
        
        for i, resource in enumerate(resources_to_process, 1):
            print(f"\nüì¶ [{i}/{len(resources_to_process)}] –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º: {resource}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
            availability = self.test_resource_availability(resource)
            available_count = sum(availability.values())
            
            if available_count == 0:
                print(f"‚ùå {resource}: –ù–µ –Ω–∞–π–¥–µ–Ω")
                continue
            
            print(f"‚úÖ {resource}: –ù–∞–π–¥–µ–Ω–æ {available_count} –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤")
            
            # –°–∫–∞—á–∏–≤–∞–µ–º –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
            for level in self.reading_levels:
                for format_type in self.output_formats:
                    key = f"{level}_{format_type}"
                    if availability.get(key, False):
                        self.stats["total_attempted"] += 1
                        result = self.download_fact_sheet(resource, level, format_type)
                        
                        if result:
                            result.update({
                                "resource": resource,
                                "level": level,
                                "format": format_type
                            })
                            all_results.append(result)
                        
                        # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Å–∫–∞—á–∏–≤–∞–Ω–∏—è–º–∏
                        time.sleep(1)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ–≥–∏ –∏ —Å–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç
        self.save_download_log(all_results)
        report = self.create_summary_report(all_results)
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print(f"\nüéâ –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   ‚Ä¢ –ù–∞–π–¥–µ–Ω–æ —Ä–µ—Å—É—Ä—Å–æ–≤: {report['summary']['total_resources']}")
        print(f"   ‚Ä¢ –°–∫–∞—á–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {self.stats['successful_downloads']}")
        print(f"   ‚Ä¢ –£–∂–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–ª–æ: {self.stats['existing_files']}")
        print(f"   ‚Ä¢ –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å: {self.stats['failed_downloads']}")
        print(f"   ‚Ä¢ –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {sum(r.get('size', 0) for r in all_results) / 1024 / 1024:.2f} MB")
        
        return report

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Å–∫—Ä–∏–ø—Ç–∞"""
    import argparse
    
    parser = argparse.ArgumentParser(description="–°–∫–∞—á–∞—Ç—å —Ñ–∞–∫—Ç-–ª–∏—Å—Ç—ã ODS")
    parser.add_argument("--limit", type=int, help="–û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ—Å—É—Ä—Å–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
    parser.add_argument("--output-dir", default="ods_fact_sheets", help="–ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
    
    args = parser.parse_args()
    
    downloader = ODSFactSheetDownloader(args.output_dir)
    report = downloader.download_all_fact_sheets(max_resources=args.limit)
    
    print(f"\n‚úÖ –í—Å–µ —Ñ–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫–µ: {downloader.base_dir}")
    print(f"üìã –°–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç: {downloader.base_dir}/summary_report.json")

if __name__ == "__main__":
    main()