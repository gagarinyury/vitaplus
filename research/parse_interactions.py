#!/usr/bin/env python3
"""
–ü–∞—Ä—Å–µ—Ä –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π –ë–ê–î–æ–≤ –∏–∑ ODS —Ñ–∞–∫—Ç-–ª–∏—Å—Ç–æ–≤
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –∏–∑ —Å–∫–∞—á–∞–Ω–Ω—ã—Ö XML —Ñ–∞–π–ª–æ–≤
"""

import os
import re
import xml.etree.ElementTree as ET
from pathlib import Path
import json
from dataclasses import dataclass, asdict
from typing import List, Dict, Optional
import html

@dataclass
class Interaction:
    supplement: str  # –ù–∞–∑–≤–∞–Ω–∏–µ –ë–ê–î–∞
    interacts_with: str  # –° —á–µ–º –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤—É–µ—Ç
    interaction_type: str  # positive/negative/neutral
    effect: str  # –û–ø–∏—Å–∞–Ω–∏–µ —ç—Ñ—Ñ–µ–∫—Ç–∞
    mechanism: str  # –ú–µ—Ö–∞–Ω–∏–∑–º –¥–µ–π—Å—Ç–≤–∏—è
    dosage_info: str  # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–æ–∑–∏—Ä–æ–≤–∫–µ
    severity: str  # low/medium/high
    source_file: str  # –ò—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª
    
class InteractionParser:
    def __init__(self, ods_directory: str):
        self.ods_dir = Path(ods_directory)
        self.interactions = []
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π
        self.interaction_keywords = [
            'interact', 'interaction', 'interfere', 'interference',
            'affect', 'reduce', 'increase', 'enhance', 'inhibit',
            'block', 'prevent', 'improve', 'decrease', 'absorption',
            'bioavailability', 'compete', 'antagonist', 'synergy'
        ]
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Ç–∏–ø–∞ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è
        self.negative_keywords = [
            'reduce', 'decrease', 'inhibit', 'block', 'prevent', 
            'interfere', 'compete', 'antagonist', 'toxic', 'harmful',
            'too much', 'too little', 'low blood', 'unsafe'
        ]
        
        self.positive_keywords = [
            'enhance', 'increase', 'improve', 'helps', 'promotes',
            'beneficial', 'synergy', 'boost', 'facilitate'
        ]

    def parse_all_files(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ –≤—Å–µ—Ö XML —Ñ–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
        xml_files = list(self.ods_dir.rglob("*.xml"))
        print(f"–ù–∞–π–¥–µ–Ω–æ {len(xml_files)} XML —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞...")
        
        for xml_file in xml_files:
            try:
                self.parse_file(xml_file)
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {xml_file.name}: {e}")
        
        print(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(self.interactions)} –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π")
        return self.interactions

    def parse_file(self, xml_file: Path):
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ XML —Ñ–∞–π–ª–∞"""
        try:
            tree = ET.parse(xml_file)
            root = tree.getroot()
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
            namespace = {'ns': 'http://tempuri.org/factsheet.xsd'}
            title_elem = root.find('.//ns:Title', namespace)
            content_elem = root.find('.//ns:Content', namespace)
            
            if title_elem is None or content_elem is None:
                return
                
            supplement_name = title_elem.text.strip()
            content = html.unescape(content_elem.text or "")
            
            # –ü–æ–∏—Å–∫ —Å–µ–∫—Ü–∏–π –æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è—Ö
            interactions_found = self.extract_interactions(content, supplement_name, xml_file.name)
            self.interactions.extend(interactions_found)
            
        except ET.ParseError as e:
            print(f"XML –æ—à–∏–±–∫–∞ –≤ {xml_file.name}: {e}")

    def extract_interactions(self, content: str, supplement_name: str, source_file: str) -> List[Interaction]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        interactions = []
        
        # –£–¥–∞–ª–µ–Ω–∏–µ HTML —Ç–µ–≥–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞
        clean_text = re.sub(r'<[^>]+>', ' ', content)
        clean_text = re.sub(r'\s+', ' ', clean_text).strip()
        
        # –ü–æ–∏—Å–∫ —Å–µ–∫—Ü–∏–π –æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è—Ö
        interaction_sections = self.find_interaction_sections(clean_text)
        
        for section in interaction_sections:
            # –†–∞–∑–±–∏–≤–∫–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
            sentences = re.split(r'[.!?]+', section)
            
            for sentence in sentences:
                if self.contains_interaction_keywords(sentence):
                    interaction = self.parse_interaction_sentence(
                        sentence, supplement_name, source_file
                    )
                    if interaction:
                        interactions.append(interaction)
        
        return interactions

    def find_interaction_sections(self, text: str) -> List[str]:
        """–ü–æ–∏—Å–∫ —Å–µ–∫—Ü–∏–π —Å –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è–º–∏"""
        sections = []
        
        # –ü–æ–∏—Å–∫ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è—Ö
        interaction_patterns = [
            r'interact with medications.*?(?=h2|$)',
            r'interact with.*?supplements.*?(?=h2|$)', 
            r'Does.*?interact.*?(?=h2|$)',
            r'interact or interfere.*?(?=h2|$)',
            r'taking.*?together.*?(?=h2|$)'
        ]
        
        for pattern in interaction_patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE | re.DOTALL)
            for match in matches:
                sections.append(match.group())
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–µ–∫—Ü–∏–∏, –∏—â–µ–º –≤ –æ–±—â–µ–º —Ç–µ–∫—Å—Ç–µ
        if not sections:
            sections = [text]
            
        return sections

    def contains_interaction_keywords(self, sentence: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è"""
        sentence_lower = sentence.lower()
        return any(keyword in sentence_lower for keyword in self.interaction_keywords)

    def parse_interaction_sentence(self, sentence: str, supplement_name: str, source_file: str) -> Optional[Interaction]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ–º"""
        sentence = sentence.strip()
        if len(sentence) < 10:  # –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
            return None
            
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–∏
        interacts_with = self.extract_interacting_substance(sentence)
        if not interacts_with:
            return None
            
        interaction_type = self.determine_interaction_type(sentence)
        effect = self.extract_effect(sentence)
        mechanism = self.extract_mechanism(sentence)
        dosage_info = self.extract_dosage_info(sentence)
        severity = self.determine_severity(sentence)
        
        return Interaction(
            supplement=supplement_name,
            interacts_with=interacts_with,
            interaction_type=interaction_type,
            effect=effect,
            mechanism=mechanism,
            dosage_info=dosage_info,
            severity=severity,
            source_file=source_file
        )

    def extract_interacting_substance(self, sentence: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤–µ—â–µ—Å—Ç–≤–∞, —Å –∫–æ—Ç–æ—Ä—ã–º –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ"""
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤–µ—â–µ—Å—Ç–≤
        patterns = [
            r'with ([A-Z][a-z]+(?:\s+[a-z]+)*)',  # with Substance
            r'and ([A-Z][a-z]+(?:\s+[a-z]+)*)',   # and Substance  
            r'taking ([A-Z][a-z]+(?:\s+[a-z]+)*)', # taking Substance
            r'([A-Z][a-z]+(?:\s+[a-z]+)*) with',   # Substance with
        ]
        
        for pattern in patterns:
            match = re.search(pattern, sentence)
            if match:
                substance = match.group(1).strip()
                if len(substance) > 2 and substance not in ['Taking', 'With', 'And']:
                    return substance
                    
        return "unknown"

    def determine_interaction_type(self, sentence: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è"""
        sentence_lower = sentence.lower()
        
        if any(keyword in sentence_lower for keyword in self.negative_keywords):
            return "negative"
        elif any(keyword in sentence_lower for keyword in self.positive_keywords):
            return "positive"
        else:
            return "neutral"

    def extract_effect(self, sentence: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ–ø–∏—Å–∞–Ω–∏—è —ç—Ñ—Ñ–µ–∫—Ç–∞"""
        # –ü–æ–∏—Å–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —ç—Ñ—Ñ–µ–∫—Ç–æ–≤
        effects = [
            r'cause ([^.]+)',
            r'might ([^.]+)', 
            r'could ([^.]+)',
            r'may ([^.]+)',
            r'can ([^.]+)'
        ]
        
        for pattern in effects:
            match = re.search(pattern, sentence, re.IGNORECASE)
            if match:
                return match.group(1).strip()
                
        return sentence[:100] + "..." if len(sentence) > 100 else sentence

    def extract_mechanism(self, sentence: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ö–∞–Ω–∏–∑–º–∞ –¥–µ–π—Å—Ç–≤–∏—è"""
        mechanisms = [
            'absorption', 'bioavailability', 'metabolism', 'excretion',
            'competition', 'binding', 'transport', 'synthesis'
        ]
        
        sentence_lower = sentence.lower()
        found_mechanisms = [m for m in mechanisms if m in sentence_lower]
        
        return ", ".join(found_mechanisms) if found_mechanisms else "unknown"

    def extract_dosage_info(self, sentence: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –¥–æ–∑–∏—Ä–æ–≤–∫–µ"""
        dosage_patterns = [
            r'(\d+\s*(?:mg|mcg|g|ug))',
            r'high dose[s]?',
            r'large amount[s]?',
            r'excessive'
        ]
        
        for pattern in dosage_patterns:
            match = re.search(pattern, sentence, re.IGNORECASE)
            if match:
                return match.group()
                
        return "not specified"

    def determine_severity(self, sentence: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç–∏ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è"""
        sentence_lower = sentence.lower()
        
        high_severity = ['toxic', 'dangerous', 'harmful', 'serious', 'severe', 'unsafe']
        medium_severity = ['reduce', 'decrease', 'interfere', 'affect']
        
        if any(word in sentence_lower for word in high_severity):
            return "high"
        elif any(word in sentence_lower for word in medium_severity):
            return "medium"
        else:
            return "low"

    def save_to_json(self, filename: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ JSON"""
        interactions_dict = [asdict(interaction) for interaction in self.interactions]
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(interactions_dict, f, ensure_ascii=False, indent=2)
        
        print(f"–í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")

    def save_to_xml(self, filename: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ XML"""
        root = ET.Element("interactions_database")
        root.set("total_interactions", str(len(self.interactions)))
        root.set("generated_from", "NIH ODS Fact Sheets")
        
        for interaction in self.interactions:
            interaction_elem = ET.SubElement(root, "interaction")
            
            for field, value in asdict(interaction).items():
                elem = ET.SubElement(interaction_elem, field)
                elem.text = str(value)
        
        tree = ET.ElementTree(root)
        tree.write(filename, encoding='utf-8', xml_declaration=True)
        
        print(f"–í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")

    def generate_summary(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–≤–æ–¥–∫–∏ –ø–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è–º"""
        if not self.interactions:
            return "–í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
            
        total = len(self.interactions)
        by_type = {}
        by_severity = {}
        by_supplement = {}
        
        for interaction in self.interactions:
            # –ü–æ —Ç–∏–ø—É
            by_type[interaction.interaction_type] = by_type.get(interaction.interaction_type, 0) + 1
            
            # –ü–æ —Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç–∏
            by_severity[interaction.severity] = by_severity.get(interaction.severity, 0) + 1
            
            # –ü–æ –ë–ê–î—É
            by_supplement[interaction.supplement] = by_supplement.get(interaction.supplement, 0) + 1
        
        summary = f"""
=== –°–í–û–î–ö–ê –ü–û –í–ó–ê–ò–ú–û–î–ï–ô–°–¢–í–ò–Ø–ú ===

–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ: {total} –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π

–ü–æ —Ç–∏–ø–∞–º:
{chr(10).join([f"- {k}: {v}" for k, v in by_type.items()])}

–ü–æ —Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç–∏:
{chr(10).join([f"- {k}: {v}" for k, v in by_severity.items()])}

–¢–æ–ø –ë–ê–î–æ–≤ —Å –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è–º–∏:
{chr(10).join([f"- {k}: {v}" for k, v in sorted(by_supplement.items(), key=lambda x: x[1], reverse=True)[:10]])}
"""
        return summary

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    ods_directory = "/Users/yurygagarin/Code/1/vitaplus/research/ods_fact_sheets"
    
    print("üîç –ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–∞ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π –ë–ê–î–æ–≤...")
    
    parser = InteractionParser(ods_directory)
    parser.parse_all_files()
    
    if parser.interactions:
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        parser.save_to_json("/Users/yurygagarin/Code/1/vitaplus/research/interactions_database.json")
        parser.save_to_xml("/Users/yurygagarin/Code/1/vitaplus/research/interactions_database.xml")
        
        # –í—ã–≤–æ–¥ —Å–≤–æ–¥–∫–∏
        print(parser.generate_summary())
    else:
        print("‚ùå –í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

if __name__ == "__main__":
    main()